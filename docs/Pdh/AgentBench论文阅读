#技术问题 暂时不会排版x
论文地址：https://arxiv.org/pdf/2308.03688.pdf
论文中评测视频演示：https://llmbench.ai/demo
AgentBench：https://github.com/THUDM/AgentBench
以下是论文中一些摘要。
  -AgentBench是一个系统的基准，用于评估大语言模型（LLM）作为代理执行实际任务的能力。
  -该团队认为关于LLM的代理能力主要包含以下部分:
   1.理解人类意图并执行指令
   2.编码能力
   3.知识获取和推理
   4.策略决策
   5.多轮一致性
   6.逻辑推理
   7.自主探索
   8.可解释的推理
  -只有LLM能完成上述具体任务，才可能承担好AI Agent的工作。
  -为此，AgentBench创建了8个不同的场景，针对上述能力来评估LLM作为Agent的表现，包括：
   1.操作系统：评估LLM在Linux系统的bash环境中的操作能力，如文件操作、用户管理等。
   2.数据库：考察LLM利用SQL操作给定的数据库完成查询、修改等任务。
   3.知识图谱：需要LLM利用给定的工具查询知识图谱，完成复杂的知识获取任务。
   4.卡牌游戏：将LLM视为玩家，根据规则和状态进行数字卡牌游戏，评估策略决策能力。
   5.横向思维难题：提供难题故事，LLM需要进行问答来推理得到真相，检查横向思维能力。
   6.家庭环境：在模拟的家中场景下，LLM需要自主完成日常任务，如搬移物品等。
   7.网络购物：按照要求在模拟购物网站上浏览和购买商品，评估自主探索决策能力。
   8.网页浏览：在真实网页环境中，根据高级指令实现操作序列，完成网页任务。
————————————————————————————————————————————
   以下是对于论文中8个不同场景的具体补充。（暂时没整理完。
1.操作系统
   -在这个数据集中，该团队旨在在真实操作系统的交互式bash环境（例如Ubuntu Docker [50]）中对LLM进行评估，针对人类提出的具有确定性答案的问题（例如，在操作系统中具有非/home目录的用户数）
    或为实际目标进行一系列操作（例如，递归地将所有目录文件设置为只读，除了我的文件）。
   -构建细节：操作系统数据集中的每个评估样本包括以下内容：
      - 指令：以自然语言描述需要LLM解决的问题。
      - Docker环境：启动Docker镜像（例如预设的默认本地操作系统/默认）。
      - 初始化脚本（可选）：需要独立执行（docker exec）的bash脚本，用于交互开始之前的操作（例如用户配置、文件、系统状态）。
      - 启动脚本（可选）：在创建shell之后、交互之前执行的bash脚本。- 检查管道：用于判断LLM答案或操作是否正确的检查方法。
      - 示例脚本（可选）：作为参考解决方案的bash脚本。换句话说，如果在交互中执行这些脚本，结果就是正确的。仅用于下面所介绍的单元测试。
   -除传统的问答（QA）评估之外，该团队在操作系统评估中设计了两种任务类型：
      - 问答（QA）：LLM需要输出命令来解决操作系统中的特定问题（例如，聚合数字，查看文件内容）。在这种情况下，它们必须最终提交答案。
      - 操作：LLM需要输出命令对操作系统进行一些可验证的操作（例如，更改文件/用户状态）。在这种情况下，它们不需要提交最终答案。由于检查管道的存在，可以用统一的解决方案评估这两种任务类型。 
   -在实践中，我们约有一半的指令是由人员创建或收集的，而另一半则是由gpt-4生成的大多数QA问题，并通过通过单元测试（即产生正确的答案/状态）进行严格过滤的。
   -对于人工指令，我们首先从Stack Overflow1中收集了6000个带有bash或shell标签的真实问题和解决方案。然后，我们根据得分（赞的数量）进行排序。我们邀请了8名专攻编程的注释员选择具有挑战性的问题。
    对于每个选定的问题，他们创建一个或多个任务指令，并编写详细的问题描述、初始化脚本、启动脚本和检查管道。最后，我们对每个评估样本进行交叉验证，以确保其正确性。对于每个问题，注释大约需要2小时。
    对于生成的问题，我们的单元测试包含以下几个部分：
      1) 初始化脚本修正：我们执行初始化脚本，并删除初始化错误的样本（即退出码不等于0的样本）。
      2) 示例代码修正：我们执行示例代码和检查管道，判断答案的正确性。我们删除答案错误的样本。
   -最后，我们精心挑选了144个高质量多样性的操作系统评估样本，并配备了测试交互环境和相应的检查找最终状态。
   -我们使用成功率衡量LLM在执行中解决问题的能力。每个问题的最终状态只有两种：错误或正确。在每个问题（即指令）的执行过程中，可以分为3个部分：
      -初始化。我们创建一个特定镜像的Docker容器，并运行一个初始化的bash脚本，以便依据指令设置环境。
      -交互。我们在Docker中启动一个新的shell，并运行指令中指定的启动bash脚本。然后，将指令和问题描述提供给要测试的LLM。LLM开始与shell进行交互。每次循环中，提供两种操作。一种是运行bash脚本，
      允许模型在shell中生成和运行一系列命令。另一种是提交答案，允许模型终止交互过程。需要注意的是，如果模型超过默认的轮数限制（默认为8轮），将判定为未能解决问题。
      -检查。对于每个问题，都有一个包含一系列脚本f1，f2，...，fn的检查管道，其中fk表示管道中的第k个脚本。对于fk，模型的答案o0和ft（t＜k）的结果ot将作为输入参数传递给fk，即ok = fk（o0，o1，
      ...，ok−1）。只有当所有脚本的退出代码均为0时，才认为结果是正确的。
  
