# 具身智能(Embodied AI)

Assignee: Lealand
Status: In Progress
Due: July 23, 2023
Project: 汪俊辰 
Priority: Low

## 具身智能

[具身智能 (Embodied AI)概述 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/620342675)

**具身（Embodiment)**：指具有支持感觉和运动（sensorimotor）的物理身体。

**具身的 （Embodied）**：具有身体的，可参与交互、感知的。

**具身智能(Embodied AI)**：有身体并支持物理交互的智能体，如家用服务机器人、无人车等。

**非具身智能（Disembodied AI）**：没有物理身体，只能被动接受人类采集、制作好的数据 。—— **“纸上谈兵”或者说 “运筹帷幄”**

**具身智能机器人**：满足具身智能的能力的机器人。

**具身任务**：像人类一样通过观察、移动、说话和与世界互动从而完成的一系列任务。

**多模态**：是指一个模型或系统能够处理多种不同类型的输入数据并融合它们生成输出。这些数据类型可能包括文本、图像、音频和视频等。

**主动交互**：机器人或智能体与环境的实时交互，从而提高智能体的学习、交流和应对问题的能力。

Google的PALM-E

UC 伯克利的 LM Nav

**具身智能机器人：首先，要能够听懂人类语言，然后，分解任务，规划子任务，移动中识别物体，与环境交互，最终完成相应任务**。理想很丰满，现实中的机器人止步于“听懂人类语言”，人们依然严重依赖手写代码来实现对机器人的控制。很明显，人-机器人交互是首当其冲的问题。

微软：Robotics Transformer for real-world control at scale

## Grounded Decoding

[Grounded Decoding](Grounded-Decoding.md)

## PALM-E

[PaLM-E: An Embodied Multimodal Language Model](PaLM-E%20An%20Embodied%20Multimodal%20Language%20Model.md)

## RT-2

[RT-2: Vision-Language-Action Models](RT-2%20Vision-Language-Action%20Models.md)